\section{Data Cleaning and Real-time Processing}

Data is coming in at different, independent rate from sensors and is produced asynchronously from internal processing elements.
For certain processes, processing the incoming data as quickly as possible is key, however, this is challenging for several reasons:
1) a process may subscribe to multiple, independent streams with asychronized report schedules and 2) interpolated values
should be avoided to minimize prediction inaccuracies in interpolated values.  Therefore, a process actually wants all the freshest
data from all the streams they are subscribing to, while minimizing the average time that the data for each respective stream has 
been waiting in the buffer.

Sensor data is fundamentally challenging to deal with because much of it must be cleaned before it can be processed.  For example,
it is not uncommon to receive readings that is out of operational range, that is erroneous with respect to the previous observed trend,
or to stop receiving readings altogether.  This implies the need for processing jobs to provide a level of filtering over the raw streams.
Once the data is cleaned, it is typically consumed more sophisticated processes that aggregate the information or use it for control
of the space or equipment.  We provide the mechanisms for handling both classes of processing jobs with our process management layer.
In the next section we will discuss our process management layer and how users can both submit jobs to StreamFS for management or link
their own external processing elements so that they can be managed through StreamFS but run outside of StreamFS.

We also discuss how we deal with the fundamental challenges that come with sensor data.  Specifically, we 
address \emph{re-sampling} and \emph{processing models}.  The incoming data does not have a common
time source, so combining the signals meaningfully involves interpolation.  There are various options that we
provide for performing the interpolation, chosen by the user depending on the units of the data.  For example,
temperature data may involve fitting a heat model with the data to attain missing values in time.  In addition,
aggregation is done as a function of the underlying constituents: they can be combined arbritarily, by adding
subtracting, multiplying or dividing corresponding values.  We provide an interface to the user that
allows them to specify how to combine the aggregate signals as a function of the child nodes in the entity-graph.
Futhermore, they can filter the data by unit.  This kind of flexibility useful for visualizing
energy consumption over time.


