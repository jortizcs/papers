
\section{Addressing BMS Shortcomings}
\label{sec:shortcomings}
The current architecture of building information systems is very tightly integrated and based on monitoring and supervisory control
of local control loops.  Building information systems were built as tightly integrated systems with a single application.  The main
layer of interaction is been the underlying network layer.  However, because of the complexity of dealing directly with the network,
later iterations of BMS's included an export feature which decoupled the protocol from the necessary information, namely, time-value
pairs for each point in the system.  As auditing applications emerged and energy became a prime target for reduction in buildings, 
these interface choices became overloaded.  Moreover, as the need to build new kind of applications emerges, the architecture pieces
that are missing become more clear.  The following is a list of some of them:

\begin{enumerate}
% \item Network protocol details should remain opaque to end-user applications.
\item Narrow waist should be above the network layer. \label{nw}
\item A time-series store is necessary. \label{ts}
\item Mechanisms to distill the readings must be availble. \label{proc}
\item Real-time data forwarding should be available, especially for control applications. \label{rt}
\item Contextual relationships between sensor should be verified. \label{cntxt}
\end{enumerate}

The first four items are commonly built and re-built in emerging applications.  Therefore, we argue that they are fundamental 
to the future architecture of building information systems.  Moreover, we observe that dealing with network-protocol specific
calls is not only cumbersome, but usually circumvented in order to deal directly with the data.  Most applications that do
use the underlying protocol expose a name-time-value (NTV) tuple to the layers above.  This observation leads us to believe that
that's where the interface should be.

The NTV layer also allows us to decouple of the data from the network protocol.  This makes it easier to include 
new sensors that may not be directly on the building network.  For example, wireless plug-load power meters~\cite{ACme}
can simply join the NTV layer by registering the individual points, while a translation layer between the NTV layer and the
main router can provide the transformation of read/write request to/from points in the network.  The same is true for BACNet
or any point protocols for sensors/actuators.

Each of the services that require the end user to have a deeper understanding of the underyling dynamics or performance
of the building \emph{must} capture the notion of time.  Almost all anlytical process or control decision needs a set of readings
over time.  Therefore, there a time-series data store must be part of future BIS design.  The service should be made available
through the NTV.  This will allow applications to fetch the necessary data for analysis either for display or complex processing.

Point \ref{proc} is motivated by the observation that sensor data, especially from cheap sensors, is dirty and typically goes
through a cleaning process before being forwarded to the end-use application.  There are various operations that are commonly
performed on the data, that we think should be provided as primitives.  These mainly include re-sampling, filtering,  
missing-data identification, and aggregation.  Re-sampling refers to taking a set of streams and interpolating missing values to 
align their timestamps.  This is typically performed before aggregation, especially for generating time-varying aggregate statistics.
Filtering simply refers to the removal of certain values based on some criteria of acceptance.  Usually the criteria is defined
by a threshold, both lower-bound and upper-bound value threshold for a particular stream or set of streams.
Since data is often missing, due to intermittent connectivity problems or faulty sensor equipment, it becomes important to 
get a summary of missing time intervals in order to adjust the fetch parameters.  Finally, the data is usually more
useful in aggregate than as a univariate signal, for example, for generating a load curve for a set of energy-consuming items.
Simple operators for combining values of various streams is key to enabling this analysis.

Finally, in order to enable control, real-time mechanisms must be exposed to the control application, while maintaining the 
layered integrity of the NTV layer.  In addition, we have observed the need to provide real-time services for analytical applications
as well.  For example, LEED is now proposing the use of building data to provide a dynamic performance meter~\cite{DynamicLeed}.
There are also many dashboard companies that make use of streaming data to provide real-time statistics on the performance of the
building.  The mobile application described in section~\ref{sec:mobile} also requires a real-time forwarding and processing service to
enable the application.  We believe that as more applications emerge they will likely need make use of real-time sensor data.

%extendible: able to add and remove stuff 
%scalable: able to scale with applications, data, and deployment size
%generalizable: able to accomodate many kinds of analytical/control applications
%ease of management: so many distributed things that it's hard to keep track of where everything lives.

The design of a new system must provide the features highlighted above in order to embody the following properties:

\begin{enumerate}

\item \emph{Extensibility}:  The system should be able to accomodate different kinds of sensors and actuators and it should
be simple for them to join and leave.

\item \emph{Scalability}:  The system should scale with the size of the deployment and the number of applications that it supports.

\item \emph{Generalizability}:  The system should provide a general set of primitives for application designers.  It should support applications
suggested in this chapter and new emerging applications that we cannot currently anticipate.

\item \emph{Ease of Management}: The system should make it easier to manage large deployments and their associated applications.

\end{enumerate}

Modern BMS architectures do not contain these properties.  They are difficult to extend, as new sensors and actuators must physically join 
the network and follow both a high-level and low-level protocol in order to do so.  They are not scalable.  Most BMS's have a limit as to
how fast they can obtain data from sensors and limit the amount of trending that the system can do.  The central outstation is the only
machine handling incoming data.  The entire code-base runs on a single machine.  There are bottlenecks throughout the system in regards to
data storage -- including the outstation memory and disk storage on the local machine that houses the BMS.  BMS's are also not generalizable.
They only support one ``applicatoin'': the graphical interface.  The GUI does have a trending/plotting option, but extending the BMS
to provide other kinds of services is impossible.  Finally, the scope of management is quite limited in BMS's and although they do provide
ease of management of sensor/actuators on the system through centralized access, we contend that the scope is simply not broad enough.

In this thesis, we will describe a new system, StreamFS, which contains the properties missing in the current architecture.  We will demonstrate 
the existence of these properties through a series of applications that were built over it in several settings.  We describe the API and
the scope and usage of the application and draw out how the capabilities enabled by StreamFS in those apps demonstrate the properties highlighted
above.

































